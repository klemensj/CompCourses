{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align =\"right\">Thomas Jefferson University <b>COMP 103</b>: Data Analysis and Visualization</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions and Summarizing Data\n",
    "\n",
    "Before diving futher into the analysis of data it is important to review some basic aspects of the math and data organization that underly statistical tests and to review some terminology that is very important to keep in mind as we move forward.\n",
    "\n",
    "## Samples vs Populations, Statistics vs Parameters, a quick review\n",
    "\n",
    "Your reading assignment included a discussion of the difference between a **sample** and a **population**. A dataset is a sample, as it includes a finite amount of data that is meant to be *representative* of some larger population. Obtaining a representative sample is one goal of the field of experimental design, which informs how scientists construct effective studies and experiments. Sampling is therefore an important part of science ... that we won't have time to cover here in any depth.\n",
    "\n",
    "Similarly a **statistic** is a value derived from a sample. When you calculate the mean, or the median, or the variance of a particular sample you are generating a **statistic**. A **parameter**, on the other hand, is the true mean or median or vaiance of a population. When we calculate a statistic for a given sample that we believe to be representative of a particular population we are doing so in order to estimate the value of a parameter. So a simple working definition of a statistic would be:\n",
    "```\n",
    "statistic = an estimate of a population parameter based on a sample.\n",
    "```\n",
    "Let's take a look at an example of estimating some parameters using the statistic we are probably most familiar with - the mean and median of a set of numbers, using a library that we are already familiar with, NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ([1,2,3,3,4])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print('mean: ', np.mean(sample))\n",
    "print('median: ',np.median(sample))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should easily be able to interpret the code above at this point. \n",
    "\n",
    "There are  a number of <a href = 'https://numpy.org/doc/stable/reference/routines.statistics.html'>commonly used statistical parameters built into numpy</a>. Given the option of calculating values within numpy or using a different library, numpy is generally faster, if that matters. \n",
    "\n",
    "\n",
    "Another library that we are familiar with is SciPy. In particular, the `scipy.stats` module contains many useful functions for working with distributions. This includes statistical *summary statistics* that we can use to estimate parameters from data, such as `mode()` and `describe()` which is a particularly useful one to know as it returns a number of statistical parameters as an object. SciPy also includes a large number of what are referred to as **probability distributions** which we will return to in a minute.\n",
    "\n",
    "Run the code below to to see these functions demonstrated and to review the description of the `scipy.stats` module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print('mode: ', stats.mode(sample))\n",
    "# print('mean: ', stats.mean(sample))\n",
    "print()\n",
    "print('describe: ', stats.describe(sample))\n",
    "print('parts of a describe object are indexable!: ', stats.describe(sample)[1])\n",
    "print('What kind of thing does describe() return: ', type(stats.describe(sample)))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "help(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Interpret the results of the code block above. \n",
    "\n",
    " * \n",
    " *\n",
    " *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample size and parameter estimation\n",
    "\n",
    "The precision with which we are able to estimate a parameter estimate is going to depend on a couple of different things: the amount of variability in the dataset we are working with and the size of the sample that we are using to estimate the parameter. This is the sample size, typically represented as 'n'.\n",
    "\n",
    "The code below generates two 1,000,000 observation data sets. We will see how to do this later, but for now what you need to know is that this data will be generated from a normal distribution (bell-shaped curve) with a mean of 5. In a normal distribution, the mean and the median are the same. The one thing that differs between the two datasets is the standard deviation. In `norm_data_1` the standard deviation is specified to be 1, and in `norm_data_2` the standard deviation is specified to be 2.\n",
    "\n",
    "We are going to treat these million observations as the true \"Population\" values of the parameters for this distribution. Take a look at the results of the code below. You should see that the values for the mean are very close to 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "norm_data_1 = norm.rvs(loc = 5, scale = 1, size = 1000000)\n",
    "norm_data_2 = norm.rvs(loc = 5, scale = 2.5, size = 1000000)\n",
    "\n",
    "def mean_print_summary(data, name = ''):              # we can use this function to check the results of our work throughout\n",
    "    print(name)\n",
    "    print('mean1: ', np.mean(data))\n",
    "    print('median1: ', np.median(data))\n",
    "    print('SD: ', np.std(data))\n",
    "    print()\n",
    "\n",
    "mean_print_summary(norm_data_1, 'norm_data_1')\n",
    "mean_print_summary(norm_data_2,'norm_data_2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the code below, in which we create a function, `explore_sample` that creates a dataset by **sampling** our population of one million randomly to create a daset of size *n*. For both data_1 and data_2 we create a number of different sized samples below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_sample(data, size):\n",
    "    sample = np.random.choice(data, size=size)\n",
    "    mean_print_summary(sample, name = ('n='+str(size)+ ' '))\n",
    "    \n",
    "    \n",
    "print('data_1')\n",
    "explore_sample(norm_data_1, 10)\n",
    "explore_sample(norm_data_1, 100)\n",
    "explore_sample(norm_data_1, 1000)\n",
    "explore_sample(norm_data_1, 10000)\n",
    "explore_sample(norm_data_1, 100000)\n",
    "\n",
    "print('data_2')\n",
    "explore_sample(norm_data_2, 10)\n",
    "explore_sample(norm_data_2, 100)\n",
    "explore_sample(norm_data_2, 1000)\n",
    "explore_sample(norm_data_2, 10000)\n",
    "explore_sample(norm_data_2, 100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Explain the code block above and tell me what it shows about the relationship between sample size and the parameter estimate. \n",
    "\n",
    " * \n",
    " *\n",
    " *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "\n",
    "\n",
    "As we saw above in the help call, `scipy.stats` contains many statistical distributions. But what does it mean that our library *contains* a distribution? And how do we use and access a statistical distribution?\n",
    "\n",
    "Distributions come in two major categories - continuous and discrete. In a continuous distribution, observations can take on any value. In a discrete distribution, data are constrained to particular values. Measuring tongue lengths on a population of bees would generate a continuous distribution. Recording the outcomes of the roll of a die would generate a discrete distribution. \n",
    "\n",
    "Discrete and continuous distributions have to be handled slightly differently in Scipy, so we are going to pick one of each to work with. Two of the most commonly seen distributions in biology are the discrete <a href='https://en.wikipedia.org/wiki/Binomial_distribution'>binomial distribution</a> and the continuous <a href='https://en.wikipedia.org/wiki/Normal_distribution'>normal distribution</a>, so we will use these as examples. \n",
    "\n",
    "The **binomial distribution** describes the occurences of a discrete event of known probability occuring over some number of repeated tests or observations. The most common example is counting the occurences of 'heads' when flipping a coin. Given the probability of flipping heads *p* (= 0.5 in the coin flip case) and some number of flips *n* the various possible outcomes will occur with some probability. The distribution can be completely described by the values of *p* and *n*. The binomial distribution can be called by `stats.binom(n,p)`. \n",
    "\n",
    "The **normal distribution** describes a continuous description in a bell shaped curve centered on the mean and the median value. It is completely described by providing a mean and the standard deviation for the distribution. It can be called using `stats.norm(loc,scale)` where `loc` is the mean of the distribution and `scale` is the standard deviation. \n",
    "\n",
    "Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "\n",
    "binomial_dist = binom(n=10, p = 5)\n",
    "normal_dist = norm(loc = 5, scale = 2.5)\n",
    "\n",
    "print(binomial_dist)\n",
    "print(normal_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that what we have created are python objects. This would be a good time to take a first look at the Scipy reference for each kind of distribution. One thing that you should notice is that there are a large number of python *methods* associated with each object. They are similar but not exactly the same. \n",
    "\n",
    "The <a href = 'https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom'>scipy.stats.binom</a> object contains the binomial distribution. \n",
    "\n",
    "The <a href = 'https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm'>scipy.stats.norm</a> object contains the normal distribution.\n",
    "\n",
    "To access information contained within each object, we will use methods. Let's take a look at the `stats()` method first, which by default will return the mean and variance of the distribution. Note that there are two different ways that we have calculated stats, one calculating the distribution on the spot, and one using the distribution name we created earlier. Go ahead and change the variables of n and p and run this a few times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 2\n",
    "p = 0.5\n",
    "\n",
    "\n",
    "mean_b, var_b = binom.stats(n,p)\n",
    "print('Binomial distribution')\n",
    "print('mean number of events ', mean_b)\n",
    "print('variance ', var_b)\n",
    "print()\n",
    "\n",
    "mean_n, var_n = normal_dist.stats()\n",
    "print('Normal distribution')\n",
    "print('mean number of observations ', mean_n)\n",
    "print('variance ', var_n , '(remember variance is standard deviation squared)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "Using the documentation, figure out how to generate different parameters from the statistical distributions using the `stats()` method and demonstrate that below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write code showing additional parameters that can be generated by the stats() method\n",
    "\n",
    "#\n",
    "# Your code goes here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling a distribution\n",
    "Another thing we can do is to sample random values from a particular distribution. (We did this above without explaining it.) The method that we use for this is `rvs(size)`, where `size` is the size of the sample we want to generate. `rvs` stands for 'Random VariateS'. Below are examples of this for the binomial and normal distributions. Play with the parameters of the distributions( n and p, loc and scale) and the `size` of the sample. What is each one telling you? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create distributions (adjust parameters here)\n",
    "binomial_dist = binom(n=10, p = 0.5)\n",
    "normal_dist = norm(loc = 5, scale = 2.5)\n",
    "\n",
    "#Sample the distributions (adjust sample size here)\n",
    "binomial_sample = binomial_dist.rvs(size =20)\n",
    "normal_sample = normal_dist.rvs(size = 20)\n",
    "\n",
    "print(binomial_sample)\n",
    "print(normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    " What is the major difference between what is being returned by rvs from the normal and binomial distributions? Read the docs, try experimenting with different numbers, but see if you can explain it in your own words below. \n",
    "\n",
    " * \n",
    " *\n",
    " *\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice visualizing distributions with histograms\n",
    "\n",
    "We have already learned the main tool for visualizing distributions - the histogram. Do the following exercises\n",
    "\n",
    "\n",
    "### Exercise 2\n",
    "Create a distribution based on the action flipping a coin 12 times and counting how many times heads comes up. Report the important statistical parameters of this distribution. Sample this distribution 100 and 500 times and create histograms of the results, which should be presented as two panels of a single figure. Be thoughtful about your bin sizes. Interpret the histogram. \n",
    "\n",
    "\n",
    "### Exercise 3\n",
    "Create a distribution of simulated bee tongue lengths. Assume the average length is 7 mm and the standard deviation is 0.8mm. Report the important statistical parameters of this distribution. Sample this distribution 100 and 500 times and create histograms of the results, which should be presented as two panels of a single figure. Be thoughtful about your bin sizes and your axes. Interpret the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Your code goes here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Your code goes here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TJU logo image](images/TJU_logo_image.png \"TJU logo image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
